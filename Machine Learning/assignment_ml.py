# -*- coding: utf-8 -*-
"""Assignment Ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10ry0o6rf-bXGoEQgThnmG2Eaas0Wnw4e
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn import preprocessing

data = pd.read_csv("/content/gender_classification_v7.csv")
data.head(5)

#check missing values
missing = data.isnull().sum()
print(missing)

label_encoder = preprocessing.LabelEncoder()
data['gender']= label_encoder.fit_transform(data['gender'])
data['gender'].unique()

x = data.iloc[:,0:-1]
y= data.iloc[:,-1]

#split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)

# Standardize features by removing the mean and scaling to unit variance
scaler = StandardScaler()
X_train = scaler.fit_transform(x_train)
X_test = scaler.transform(x_test)

"""#KNN"""

KNN = KNeighborsClassifier(n_neighbors =3)
KNN.fit(x_train,y_train)

y_pred_train_KNN = KNN.predict(x_test)

train_acc_KNN=  metrics.accuracy_score(y_test, y_pred_train_KNN)
print('Training Accuracy: \n', train_acc_KNN*100, '%')

"""#Naive Bayes"""

Gaussian = GaussianNB()
Gaussian.fit(x_train,y_train)

y_pred_train_Gaussian = Gaussian.predict(x_test)

train_acc_Gaussian =  metrics.accuracy_score(y_test, y_pred_train_Gaussian)
print('Training Accuracy: \n', train_acc_Gaussian*100, '%')

"""#LogisticRegression"""

Logistic = LogisticRegression(max_iter=1000)
Logistic.fit(x_train,y_train)

y_pred_Logistic = Logistic.predict(x_test)

train_acc_Logistic =  metrics.accuracy_score(y_test, y_pred_Logistic)
print('Training Accuracy: \n', train_acc_Logistic*100, '%')

"""#ROC"""

# ROC Curve and AUC for KNN
y_pred_proba_KNN = KNN.predict_proba(x_test)[:,1]
fpr_KNN, tpr_KNN, _ = roc_curve(y_test, y_pred_proba_KNN)
auc_KNN = auc(fpr_KNN, tpr_KNN)

# ROC Curve and AUC for Gaussian Naive Bayes
y_pred_proba_Gaussian = Gaussian.predict_proba(x_test)[:,1]
fpr_Gaussian, tpr_Gaussian, _ = roc_curve(y_test, y_pred_proba_Gaussian)
auc_Gaussian = auc(fpr_Gaussian, tpr_Gaussian)

# ROC Curve and AUC for Logistic Regression
y_pred_proba_Logistic = Logistic.predict_proba(x_test)[:,1]
fpr_Logistic, tpr_Logistic, _ = roc_curve(y_test, y_pred_proba_Logistic)
auc_Logistic = auc(fpr_Logistic, tpr_Logistic)

# Plot ROC curves
plt.figure(figsize=(8, 6))
plt.plot(fpr_KNN, tpr_KNN, label=f'KNN (AUC = {auc_KNN:.2f})')
plt.plot(fpr_Gaussian, tpr_Gaussian, label=f'Gaussian Naive Bayes (AUC = {auc_Gaussian:.2f})')
plt.plot(fpr_Logistic, tpr_Logistic, label=f'Logistic Regression (AUC = {auc_Logistic:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()